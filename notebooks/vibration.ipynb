{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0a24e6af-3b17-4a02-afce-1f85cf876c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "path = \"./data/vibrate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "78177e10-2899-47e5-8fe0-27dd1690d3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor1 = pd.read_csv(path+'/g1_sensor1.csv', names = ['time', 'normal', 'type1', 'type2', 'type3'])\n",
    "sensor2 = pd.read_csv(path+'/g1_sensor2.csv', names = ['time', 'normal', 'type1', 'type2', 'type3'])\n",
    "sensor3 = pd.read_csv(path+'/g1_sensor3.csv', names = ['time', 'normal', 'type1', 'type2', 'type3'])\n",
    "sensor4 = pd.read_csv(path+'/g1_sensor4.csv', names = ['time', 'normal', 'type1', 'type2', 'type3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cca05b90-8388-4504-8d4a-ec3a14273729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensor 1의 데이터 크기 (190218, 5)\n",
      "sensor 2의 데이터 크기 (184211, 5)\n",
      "sensor 3의 데이터 크기 (196079, 5)\n",
      "sensor 4의 데이터 크기 (183969, 5)\n"
     ]
    }
   ],
   "source": [
    "print('sensor 1의 데이터 크기', sensor1.shape)\n",
    "print('sensor 2의 데이터 크기', sensor2.shape)\n",
    "print('sensor 3의 데이터 크기', sensor3.shape)\n",
    "print('sensor 4의 데이터 크기', sensor4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c669adc-5313-437d-a74b-b13def7bf0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "x_new = np.arange(0, 140, 0.001)\n",
    "y_new1 = []; y_new2 = []; y_new3 = []; y_new4 = []\n",
    "for item in ['normal', 'type1', 'type2', 'type3']:\n",
    "    f_linear1 = interpolate.interp1d(sensor1['time'], sensor1[item], kind='linear')\n",
    "    f_linear2 = interpolate.interp1d(sensor2['time'], sensor2[item], kind='linear')\n",
    "    f_linear3 = interpolate.interp1d(sensor3['time'], sensor3[item], kind='linear')\n",
    "    f_linear4 = interpolate.interp1d(sensor4['time'], sensor4[item], kind='linear')\n",
    "\n",
    "    y_new1.append(f_linear1(x_new))\n",
    "    y_new2.append(f_linear2(x_new))\n",
    "    y_new3.append(f_linear3(x_new))\n",
    "    y_new4.append(f_linear4(x_new))\n",
    "\n",
    "sensor1 = pd.DataFrame(np.array(y_new1).T, columns = ['normal', 'type1', 'type2', 'type3'])\n",
    "sensor2 = pd.DataFrame(np.array(y_new2).T, columns = ['normal', 'type1', 'type2', 'type3'])\n",
    "sensor3 = pd.DataFrame(np.array(y_new3).T, columns = ['normal', 'type1', 'type2', 'type3'])\n",
    "sensor4 = pd.DataFrame(np.array(y_new4).T, columns = ['normal', 'type1', 'type2', 'type3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fde8fa43-1f35-41ab-8be1-a96c58c66c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_ = pd.concat([sensor1['normal'], sensor2['normal'], sensor3['normal'],\n",
    "sensor4['normal']], axis=1)\n",
    "type1_ = pd.concat([sensor1['type1'], sensor2['type1'], sensor3['type1'],\n",
    "sensor4['type1']], axis=1)\n",
    "type2_ = pd.concat([sensor1['type2'], sensor2['type2'], sensor3['type2'],\n",
    "sensor4['type2']], axis=1)\n",
    "type3_ = pd.concat([sensor1['type3'], sensor2['type3'], sensor3['type3'],\n",
    "sensor4['type3']], axis=1)\n",
    "normal_.columns = ['s1', 's2', 's3', 's4']; type1_.columns = ['s1', 's2', 's3', 's4']\n",
    "type2_.columns = ['s1', 's2', 's3', 's4']; type3_.columns = ['s1', 's2', 's3', 's4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "80b6958f-8a15-4592-bf91-3edced39eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "M =15\n",
    "normal_s1 = np.convolve(normal_['s1'], np.ones(M), 'valid') / M; normal_s1 = normal_s1.reshape(len(normal_s1),1)\n",
    "normal_s2 = np.convolve(normal_['s2'], np.ones(M), 'valid') / M; normal_s2 = normal_s2.reshape(len(normal_s2),1)\n",
    "normal_s3 = np.convolve(normal_['s3'], np.ones(M), 'valid') / M; normal_s3 = normal_s3.reshape(len(normal_s3),1)\n",
    "normal_s4 = np.convolve(normal_['s4'], np.ones(M), 'valid') / M; normal_s4 = normal_s4.reshape(len(normal_s4),1)\n",
    "type1_s1 = np.convolve(type1_['s1'], np.ones(M), 'valid') / M; type1_s1 = type1_s1.reshape(len(type1_s1),1)\n",
    "type1_s2 = np.convolve(type1_['s2'], np.ones(M), 'valid') / M; type1_s2 = type1_s2.reshape(len(type1_s2),1)\n",
    "type1_s3 = np.convolve(type1_['s3'], np.ones(M), 'valid') / M; type1_s3 = type1_s3.reshape(len(type1_s3),1)\n",
    "type1_s4 = np.convolve(type1_['s4'], np.ones(M), 'valid') / M; type1_s4 = type1_s4.reshape(len(type1_s4),1)\n",
    "type2_s1 = np.convolve(type2_['s1'], np.ones(M), 'valid') / M; type2_s1 = type2_s1.reshape(len(type2_s1),1)\n",
    "type2_s2 = np.convolve(type2_['s2'], np.ones(M), 'valid') / M; type2_s2 = type2_s2.reshape(len(type2_s2),1)\n",
    "type2_s3 = np.convolve(type2_['s3'], np.ones(M), 'valid') / M; type2_s3 = type2_s3.reshape(len(type2_s3),1)\n",
    "type2_s4 = np.convolve(type2_['s4'], np.ones(M), 'valid') / M; type2_s4 = type2_s4.reshape(len(type2_s4),1)\n",
    "type3_s1 = np.convolve(type3_['s1'], np.ones(M), 'valid') / M; type3_s1 = type3_s1.reshape(len(type3_s1),1)\n",
    "type3_s2 = np.convolve(type3_['s2'], np.ones(M), 'valid') / M; type3_s2 = type3_s2.reshape(len(type3_s2),1)\n",
    "type3_s3 = np.convolve(type3_['s3'], np.ones(M), 'valid') / M; type3_s3 = type3_s3.reshape(len(type3_s3),1)\n",
    "type3_s4 = np.convolve(type3_['s4'], np.ones(M), 'valid') / M; type3_s4 = type3_s4.reshape(len(type3_s4),1)\n",
    "normal_temp = np.concatenate((normal_s1,normal_s2,normal_s3,normal_s4), axis =1)\n",
    "type1_temp = np.concatenate((type1_s1,type1_s2,type1_s3,type1_s4), axis =1)\n",
    "type2_temp = np.concatenate((type2_s1,type2_s2,type2_s3,type2_s4), axis =1)\n",
    "type3_temp = np.concatenate((type3_s1,type3_s2,type3_s3,type3_s4), axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f30caad0-808c-4d18-be24-e2bc112371ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(normal_)\n",
    "normal = scaler.transform(normal_temp)\n",
    "type1 = scaler.transform(type1_temp)\n",
    "type2 = scaler.transform(type2_temp)\n",
    "type3 = scaler.transform(type3_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e70b44fe-85dc-429a-9f1e-30e28ec21cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data의 형태: (240000, 4)\n",
      "valid data의 형태: (80000, 4)\n",
      " test data의 형태: (239944, 4)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분배\n",
    "normal_train = normal[:][:60000]; normal_valid = normal[:][60000:80000]; normal_test = normal[:][80000:]\n",
    "type1_train = type1[:][:60000]; type1_valid = type1[:][60000:80000]; type1_test = type1[:][80000:]\n",
    "type2_train = type2[:][:60000]; type2_valid = type2[:][60000:80000]; type2_test = type2[:][80000:]\n",
    "type3_train = type3[:][:60000]; type3_valid = type3[:][60000:80000]; type3_test = type3[:][80000:]\n",
    "train = np.concatenate((normal_train,type1_train,type2_train,type3_train))\n",
    "valid = np.concatenate((normal_valid,type1_valid,type2_valid,type3_valid))\n",
    "test = np.concatenate((normal_test,type1_test,type2_test,type3_test))\n",
    "print(\"train data의 형태:\", train.shape)\n",
    "print(\"valid data의 형태:\", valid.shape)\n",
    "print(\" test data의 형태:\", test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
